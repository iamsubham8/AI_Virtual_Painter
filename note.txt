#AI VIRTUAL PAINTER


1. Libraries and Setup
import cv2
import numpy as np
import mediapipe as mp
from collections import deque
•	cv2: OpenCV for image/video handling and GUI.
•	numpy: For matrix operations, used for creating a canvas.
•	mediapipe: From Google — used here to detect and track hand landmarks.
•	deque: Efficient structure from collections to store points (used to store multiple drawing strokes).


2. Color Buffers for Drawing
bpoints = [deque(maxlen=1024)]
gpoints = [deque(maxlen=1024)]
rpoints = [deque(maxlen=1024)]
ypoints = [deque(maxlen=1024)]
Each color has a list of deques (think of them as strokes). These store the drawing points in the selected color. maxlen=1024 limits stroke length.

blue_index = 0
green_index = 0
red_index = 0
yellow_index = 0
These indexes keep track of the current stroke for each color.

3. UI and Canvas Initialization
paintWindow = np.zeros((471,636,3)) + 255
Creates a white canvas (471x636, 3 channels for RGB).
Then rectangles are drawn at the top to serve as buttons for:
•	CLEAR
•	BLUE
•	GREEN
•	RED
•	YELLOW
Text is added on top of each rectangle using cv2.putText.
colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (0, 255, 255)]
colorIndex = 0  # starts with blue
These define BGR values for each color.


4. MediaPipe Hand Detection Setup

mpHands = mp.solutions.hands
hands = mpHands.Hands(max_num_hands=1, min_detection_confidence=0.7)
mpDraw = mp.solutions.drawing_utils
•	Configures hand tracking with a maximum of 1 hand and 70% confidence threshold.
•	mpDraw is used to draw landmarks.





5. Webcam Feed Loop
cap = cv2.VideoCapture(0)
Starts capturing webcam video.
Inside the loop:

ret, frame = cap.read()
frame = cv2.flip(frame, 1)
framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
•	Reads a frame from webcam.
•	Flips it horizontally so it behaves like a mirror.
•	Converts to RGB for MediaPipe processing.

6. Hand Landmark Processing
result = hands.process(framergb)
•	Detects hands in the frame.
•	If hand is detected: loop through landmarks, which are 21 key points on the hand.
•	Calculate (x, y) coordinates of each landmark by scaling normalized values with frame size.

fore_finger = (landmarks[8][0],landmarks[8][1])  # Index fingertip
thumb = (landmarks[4][0],landmarks[4][1])        # Thumb tip

These are used to determine gestures.




 7. Gesture-Based Drawing Logic
•	If index and thumb are close together (thumb[1] - center[1] < 30), it's treated as a non-drawing state (pause or lift pen). A new stroke deque is started for each color.
•	If index fingertip is in the top UI area (center[1] <= 65):
o	Depending on the x position, it can trigger:
	CLEAR: clears the canvas and resets buffers.
	Color change: sets colorIndex.
•	Else (normal case), the current center point is added to the current deque for the selected color.

8. Drawing the Lines
for i in range(len(points)):
    for j in range(len(points[i])):
        for k in range(1, len(points[i][j])):
            ...
            cv2.line(...)
This loop:
•	Goes through all deques (strokes) of all color buffers.
•	Draws each stroke segment using cv2.line() on both the:
o	frame (live camera view)
o	paintWindow (persistent canvas)



 9. Show Windows and Quit
cv2.imshow("Output", frame) 
cv2.imshow("Paint", paintWindow)

if cv2.waitKey(1) == ord('q'):
    break
Displays two windows:
•	Output: live webcam feed with drawing overlay.
•	Paint: persistent canvas.
Press q to quit.

10. Cleanup
cap.release()
cv2.destroyAllWindows()
Frees webcam and closes all OpenCV windows.


Summary: What It Does
This program creates a virtual drawing app using:
•	Hand tracking (MediaPipe)
•	OpenCV UI
•	Real-time gesture control
Use your index finger to draw, and touch your thumb to stop drawing or change color. It's like drawing in the air with an invisible pen!

